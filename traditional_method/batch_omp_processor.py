"""
æ‰¹é‡OMPå¤„ç†å™¨
=============

ç”¨äºæ‰¹é‡å¤„ç†MSTARæ•°æ®é›†ï¼Œæ¯”è¾ƒä¸åŒOMPé…ç½®çš„æ€§èƒ½ï¼Œ
å¹¶ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Šã€‚
"""

import os
import sys
import time
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from concurrent.futures import ProcessPoolExecutor, as_completed
import warnings

warnings.filterwarnings("ignore")

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

from traditional_method.omp_asc_extractor import OMPASCExtractor
from traditional_method.omp_config import get_config, list_available_configs
from utils.reconstruction import extract_scatterers_from_mat


class BatchOMPProcessor:
    """æ‰¹é‡OMPå¤„ç†å™¨"""

    def __init__(self, data_root=None, output_root=None):
        """
        åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨

        Parameters:
        -----------
        data_root : str, optional
            MSTARæ•°æ®æ ¹ç›®å½•
        output_root : str, optional
            è¾“å‡ºç»“æœæ ¹ç›®å½•
        """
        if data_root is None:
            self.data_root = os.path.join(project_root, "datasets", "SAR_ASC_Project")
        else:
            self.data_root = data_root

        if output_root is None:
            self.output_root = os.path.join(project_root, "traditional_method", "batch_results")
        else:
            self.output_root = output_root

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_root, exist_ok=True)

        self.mat_root = os.path.join(self.data_root, "01_Data_Processed_mat_part-tmp")
        self.raw_root = os.path.join(self.data_root, "02_Data_Processed_raw")
        self.gt_asc_root = os.path.join(self.data_root, "03_Training_ASC")

        print(f"ğŸ¯ æ‰¹é‡OMPå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   æ•°æ®æ ¹ç›®å½•: {self.data_root}")
        print(f"   è¾“å‡ºæ ¹ç›®å½•: {self.output_root}")

    def find_test_files(self, max_files=None, file_pattern=None):
        """
        æŸ¥æ‰¾æµ‹è¯•æ–‡ä»¶

        Parameters:
        -----------
        max_files : int, optional
            æœ€å¤§å¤„ç†æ–‡ä»¶æ•°
        file_pattern : str, optional
            æ–‡ä»¶åæ¨¡å¼è¿‡æ»¤

        Returns:
        --------
        list
            æµ‹è¯•æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
        """
        test_files = []

        if not os.path.exists(self.mat_root):
            print(f"âŒ MATæ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.mat_root}")
            return test_files

        for root, dirs, files in os.walk(self.mat_root):
            for file in files:
                if file.endswith(".mat"):
                    if file_pattern and file_pattern not in file:
                        continue

                    mat_path = os.path.join(root, file)

                    # æŸ¥æ‰¾å¯¹åº”çš„GT ASCæ–‡ä»¶
                    rel_path = os.path.relpath(root, self.mat_root)
                    base_name = os.path.splitext(file)[0]

                    gt_asc_path = None
                    if os.path.exists(self.gt_asc_root):
                        gt_asc_candidate = os.path.join(self.gt_asc_root, rel_path, base_name + ".mat")
                        if os.path.exists(gt_asc_candidate):
                            gt_asc_path = gt_asc_candidate

                    test_files.append(
                        {"mat_path": mat_path, "gt_asc_path": gt_asc_path, "base_name": base_name, "rel_path": rel_path}
                    )

                    if max_files and len(test_files) >= max_files:
                        break

            if max_files and len(test_files) >= max_files:
                break

        print(f"ğŸ“ æ‰¾åˆ° {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶")
        if gt_asc_path:
            gt_count = sum(1 for f in test_files if f["gt_asc_path"] is not None)
            print(f"   å…¶ä¸­ {gt_count} ä¸ªæ–‡ä»¶æœ‰å¯¹åº”çš„GT ASCæ ‡æ³¨")

        return test_files

    def process_single_file(self, file_info, config_name, extractor=None):
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶

        Parameters:
        -----------
        file_info : dict
            æ–‡ä»¶ä¿¡æ¯
        config_name : str
            é…ç½®åç§°
        extractor : OMPASCExtractor, optional
            OMPæå–å™¨å®ä¾‹

        Returns:
        --------
        dict
            å¤„ç†ç»“æœ
        """
        if extractor is None:
            config = get_config(config_name)
            omp_params = config["omp_params"]

            extractor = OMPASCExtractor(
                img_size=config["image_params"]["img_size"],
                search_region=omp_params["search_region"],
                grid_resolution=omp_params["grid_resolution"],
                amplitude_range=(0.1, 10.0),
                alpha_range=omp_params["alpha_range"],
                n_nonzero_coefs=omp_params["n_nonzero_coefs"],
                cross_validation=omp_params["cross_validation"],
            )

        result = {
            "file_info": file_info,
            "config_name": config_name,
            "success": False,
            "error_message": None,
            "processing_time": 0,
            "n_detected_scatterers": 0,
            "n_gt_scatterers": 0,
            "reconstruction_metrics": {},
            "detected_asc": [],
            "gt_asc": [],
        }

        try:
            start_time = time.time()

            # æå–ASC
            asc_list = extractor.extract_asc_from_mat(file_info["mat_path"])

            processing_time = time.time() - start_time

            result.update(
                {
                    "success": True,
                    "processing_time": processing_time,
                    "n_detected_scatterers": len(asc_list),
                    "detected_asc": asc_list,
                }
            )

            # è¯»å–GT ASCï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if file_info["gt_asc_path"]:
                try:
                    gt_asc = extract_scatterers_from_mat(file_info["gt_asc_path"])
                    result["gt_asc"] = gt_asc
                    result["n_gt_scatterers"] = len(gt_asc)
                except Exception as e:
                    print(f"âš ï¸ è¯»å–GT ASCå¤±è´¥: {e}")

            # è®¡ç®—é‡å»ºè´¨é‡æŒ‡æ ‡
            if asc_list:
                try:
                    import scipy.io as sio

                    mat_data = sio.loadmat(file_info["mat_path"])
                    original_img = mat_data["Img"] * np.exp(1j * mat_data["phase"])

                    recon_img = extractor.reconstruct_image_from_asc(asc_list)
                    metrics = extractor.evaluate_reconstruction(original_img, recon_img)
                    result["reconstruction_metrics"] = metrics
                except Exception as e:
                    print(f"âš ï¸ é‡å»ºè¯„ä¼°å¤±è´¥: {e}")

        except Exception as e:
            result.update({"success": False, "error_message": str(e)})

        return result

    def batch_process(self, config_names=["standard"], max_files=10, parallel=False):
        """
        æ‰¹é‡å¤„ç†å¤šä¸ªé…ç½®

        Parameters:
        -----------
        config_names : list
            é…ç½®åç§°åˆ—è¡¨
        max_files : int
            æœ€å¤§å¤„ç†æ–‡ä»¶æ•°
        parallel : bool
            æ˜¯å¦å¹¶è¡Œå¤„ç†

        Returns:
        --------
        dict
            æ‰¹é‡å¤„ç†ç»“æœ
        """
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†")
        print(f"   é…ç½®æ–¹æ¡ˆ: {config_names}")
        print(f"   æœ€å¤§æ–‡ä»¶æ•°: {max_files}")
        print(f"   å¹¶è¡Œå¤„ç†: {parallel}")

        # æŸ¥æ‰¾æµ‹è¯•æ–‡ä»¶
        test_files = self.find_test_files(max_files=max_files)
        if not test_files:
            print("âŒ æœªæ‰¾åˆ°æµ‹è¯•æ–‡ä»¶")
            return {}

        all_results = {}

        for config_name in config_names:
            print(f"\nğŸ“Š å¤„ç†é…ç½®: {config_name}")
            print("-" * 40)

            config_results = []

            # ä¸²è¡Œå¤„ç†
            for file_info in tqdm(test_files, desc=f"å¤„ç†{config_name}"):
                result = self.process_single_file(file_info, config_name)
                config_results.append(result)

            all_results[config_name] = config_results

            # æ‰“å°é…ç½®æ‘˜è¦
            self._print_config_summary(config_name, config_results)

        # ä¿å­˜ç»“æœ
        self._save_batch_results(all_results)

        # ç”Ÿæˆæ¯”è¾ƒæŠ¥å‘Š
        if len(all_results) > 1:
            self._generate_comparison_report(all_results)

        return all_results

    def _print_config_summary(self, config_name, results):
        """æ‰“å°é…ç½®å¤„ç†æ‘˜è¦"""
        successful_results = [r for r in results if r["success"]]
        n_success = len(successful_results)
        n_total = len(results)

        if n_success > 0:
            avg_time = np.mean([r["processing_time"] for r in successful_results])
            avg_scatterers = np.mean([r["n_detected_scatterers"] for r in successful_results])

            # é‡å»ºè´¨é‡ç»Ÿè®¡
            rmse_values = [
                r["reconstruction_metrics"].get("relative_rmse", float("inf"))
                for r in successful_results
                if r["reconstruction_metrics"]
            ]
            avg_rmse = np.mean(rmse_values) if rmse_values else float("inf")

            print(f"âœ… é…ç½® {config_name} å¤„ç†å®Œæˆ:")
            print(f"   æˆåŠŸç‡: {n_success}/{n_total} ({n_success/n_total*100:.1f}%)")
            print(f"   å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.2f}ç§’")
            print(f"   å¹³å‡æ£€æµ‹æ•£å°„ä¸­å¿ƒæ•°: {avg_scatterers:.1f}")
            print(f"   å¹³å‡é‡å»ºRMSE: {avg_rmse:.4f}")
        else:
            print(f"âŒ é…ç½® {config_name} å…¨éƒ¨å¤„ç†å¤±è´¥")

    def _save_batch_results(self, all_results):
        """ä¿å­˜æ‰¹é‡å¤„ç†ç»“æœ"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")

        # ä¿å­˜æ‘˜è¦ç»Ÿè®¡ï¼ˆCSVæ ¼å¼ï¼‰
        summary_data = []
        for config_name, results in all_results.items():
            successful_results = [r for r in results if r["success"]]

            if successful_results:
                summary_data.append(
                    {
                        "config_name": config_name,
                        "n_files": len(results),
                        "n_success": len(successful_results),
                        "success_rate": len(successful_results) / len(results),
                        "avg_processing_time": np.mean([r["processing_time"] for r in successful_results]),
                        "std_processing_time": np.std([r["processing_time"] for r in successful_results]),
                        "avg_detected_scatterers": np.mean([r["n_detected_scatterers"] for r in successful_results]),
                        "std_detected_scatterers": np.std([r["n_detected_scatterers"] for r in successful_results]),
                        "avg_rmse": np.mean(
                            [
                                r["reconstruction_metrics"].get("relative_rmse", float("inf"))
                                for r in successful_results
                                if r["reconstruction_metrics"]
                            ]
                        ),
                        "avg_correlation": np.mean(
                            [
                                r["reconstruction_metrics"].get("correlation", 0)
                                for r in successful_results
                                if r["reconstruction_metrics"]
                            ]
                        ),
                    }
                )

        if summary_data:
            summary_df = pd.DataFrame(summary_data)
            summary_file = os.path.join(self.output_root, f"batch_summary_{timestamp}.csv")
            summary_df.to_csv(summary_file, index=False)
            print(f"ğŸ“Š æ‘˜è¦ç»Ÿè®¡å·²ä¿å­˜åˆ°: {summary_file}")

    def _generate_comparison_report(self, all_results):
        """ç”Ÿæˆæ¯”è¾ƒåˆ†ææŠ¥å‘Š"""
        if len(all_results) < 2:
            print("âš ï¸ éœ€è¦è‡³å°‘2ä¸ªé…ç½®æ‰èƒ½ç”Ÿæˆæ¯”è¾ƒæŠ¥å‘Š")
            return

        print("\nğŸ“ˆ ç”Ÿæˆæ¯”è¾ƒåˆ†ææŠ¥å‘Š...")

        # åˆ›å»ºæ¯”è¾ƒå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle("OMPé…ç½®æ€§èƒ½æ¯”è¾ƒåˆ†æ", fontsize=16, fontweight="bold")

        config_names = list(all_results.keys())
        colors = plt.cm.Set1(np.linspace(0, 1, len(config_names)))

        # 1. å¤„ç†æ—¶é—´æ¯”è¾ƒ
        ax = axes[0, 0]
        processing_times = []
        labels = []
        for config_name in config_names:
            successful_results = [r for r in all_results[config_name] if r["success"]]
            times = [r["processing_time"] for r in successful_results]
            if times:
                processing_times.append(times)
                labels.append(config_name)

        if processing_times:
            ax.boxplot(processing_times, labels=labels)
            ax.set_title("å¤„ç†æ—¶é—´åˆ†å¸ƒ")
            ax.set_ylabel("æ—¶é—´ (ç§’)")
            ax.tick_params(axis="x", rotation=45)

        # 2. æ£€æµ‹æ•£å°„ä¸­å¿ƒæ•°æ¯”è¾ƒ
        ax = axes[0, 1]
        scatterer_counts = []
        for config_name in config_names:
            successful_results = [r for r in all_results[config_name] if r["success"]]
            counts = [r["n_detected_scatterers"] for r in successful_results]
            if counts:
                scatterer_counts.append(counts)

        if scatterer_counts:
            ax.boxplot(scatterer_counts, labels=labels)
            ax.set_title("æ£€æµ‹æ•£å°„ä¸­å¿ƒæ•°åˆ†å¸ƒ")
            ax.set_ylabel("æ•£å°„ä¸­å¿ƒæ•°")
            ax.tick_params(axis="x", rotation=45)

        # 3. æˆåŠŸç‡æ¯”è¾ƒ
        ax = axes[1, 0]
        success_rates = []
        for config_name in config_names:
            results = all_results[config_name]
            success_rate = sum(1 for r in results if r["success"]) / len(results)
            success_rates.append(success_rate)

        bars = ax.bar(config_names, success_rates, color=colors)
        ax.set_title("å¤„ç†æˆåŠŸç‡")
        ax.set_ylabel("æˆåŠŸç‡")
        ax.set_ylim(0, 1.1)
        ax.tick_params(axis="x", rotation=45)

        # 4. å¤„ç†æ—¶é—´ vs æ•£å°„ä¸­å¿ƒæ•°
        ax = axes[1, 1]
        for i, config_name in enumerate(config_names):
            successful_results = [r for r in all_results[config_name] if r["success"]]
            times = [r["processing_time"] for r in successful_results]
            counts = [r["n_detected_scatterers"] for r in successful_results]

            if times and counts:
                ax.scatter(times, counts, label=config_name, color=colors[i], alpha=0.7)

        ax.set_xlabel("å¤„ç†æ—¶é—´ (ç§’)")
        ax.set_ylabel("æ£€æµ‹æ•£å°„ä¸­å¿ƒæ•°")
        ax.set_title("å¤„ç†æ—¶é—´ vs æ£€æµ‹æ•°é‡")
        ax.legend()

        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        report_file = os.path.join(self.output_root, f"comparison_report_{timestamp}.png")
        plt.savefig(report_file, dpi=300, bbox_inches="tight")
        print(f"ğŸ“Š æ¯”è¾ƒæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

        plt.show()


def main():
    """ä¸»å‡½æ•°ï¼šæ‰¹é‡å¤„ç†æ¼”ç¤º"""
    print("ğŸš€ æ‰¹é‡OMPå¤„ç†å™¨æ¼”ç¤º")
    print("=" * 50)

    # åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨
    processor = BatchOMPProcessor()

    # åˆ—å‡ºå¯ç”¨é…ç½®
    print("\nğŸ”§ å¯ç”¨é…ç½®:")
    list_available_configs()

    # æ‰¹é‡å¤„ç†å¤šä¸ªé…ç½®
    config_names = ["debug", "fast", "standard"]  # é€‰æ‹©å‡ ä¸ªé…ç½®è¿›è¡Œæ¯”è¾ƒ
    max_files = 5  # é™åˆ¶æ–‡ä»¶æ•°ä»¥å‡å°‘æ¼”ç¤ºæ—¶é—´

    print(f"\nğŸ¯ å¼€å§‹æ‰¹é‡å¤„ç†æ¼”ç¤º")
    print(f"   é€‰æ‹©é…ç½®: {config_names}")
    print(f"   æœ€å¤§æ–‡ä»¶æ•°: {max_files}")

    try:
        results = processor.batch_process(
            config_names=config_names,
            max_files=max_files,
            parallel=False,  # æ¼”ç¤ºæ—¶ä½¿ç”¨ä¸²è¡Œå¤„ç†
        )

        if results:
            print("\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
            print("   è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°è¾“å‡ºç›®å½•")
        else:
            print("\nâŒ æ‰¹é‡å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„")

    except Exception as e:
        print(f"\nâŒ æ‰¹é‡å¤„ç†å‡ºé”™: {e}")


if __name__ == "__main__":
    main()
