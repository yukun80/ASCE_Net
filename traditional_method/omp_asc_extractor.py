"""
OMP-based ASC Extractor for MSTAR Dataset
==========================================

å®ç°åŸºäºæ­£äº¤åŒ¹é…è¿½è¸ª(OMP)ç®—æ³•çš„æ•£å°„ä¸­å¿ƒæå–å™¨ï¼Œç”¨äºMSTARæ•°æ®é›†ã€‚
è¯¥å®ç°ä½¿ç”¨scikit-learnçš„å®˜æ–¹OMPå®ç°ï¼Œç»“åˆSARæˆåƒç‰©ç†æ¨¡å‹ã€‚

ä½œè€…: SARç®—æ³•å·¥ç¨‹å¸ˆ
æ—¥æœŸ: 2025å¹´1æœˆ
"""

import os
import sys
import numpy as np
import scipy.io as sio
from scipy.signal.windows import taylor
from scipy.ndimage import maximum_filter
import matplotlib.pyplot as plt
from sklearn.linear_model import OrthogonalMatchingPursuit, OrthogonalMatchingPursuitCV
from sklearn.preprocessing import normalize
from tqdm import tqdm
import warnings

warnings.filterwarnings("ignore")

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

from utils import config


class OMPASCExtractor:
    """åŸºäºOMPç®—æ³•çš„æ•£å°„ä¸­å¿ƒæå–å™¨"""

    def __init__(
        self,
        img_size=(128, 128),
        search_region=(-6.4, 6.4, -6.4, 6.4),  # (x_min, x_max, y_min, y_max) in meters
        grid_resolution=0.2,  # ç½‘æ ¼åˆ†è¾¨ç‡ (ç±³)
        amplitude_range=(0.1, 10.0),  # å¹…åº¦æœç´¢èŒƒå›´
        alpha_range=(-2.0, 2.0),  # Alphaå‚æ•°æœç´¢èŒƒå›´
        n_nonzero_coefs=20,  # OMPç¨€ç–åº¦æ§åˆ¶
        cross_validation=True,
    ):
        """
        åˆå§‹åŒ–OMP ASCæå–å™¨

        Parameters:
        -----------
        img_size : tuple
            å›¾åƒå°ºå¯¸ (height, width)
        search_region : tuple
            æœç´¢åŒºåŸŸ (x_min, x_max, y_min, y_max) å•ä½ï¼šç±³
        grid_resolution : float
            ç©ºé—´ç½‘æ ¼åˆ†è¾¨ç‡ï¼Œå•ä½ï¼šç±³
        amplitude_range : tuple
            å¹…åº¦æœç´¢èŒƒå›´
        alpha_range : tuple
            Alphaå‚æ•°æœç´¢èŒƒå›´
        n_nonzero_coefs : int
            OMPç®—æ³•çš„ç¨€ç–åº¦å‚æ•°
        cross_validation : bool
            æ˜¯å¦ä½¿ç”¨äº¤å‰éªŒè¯è‡ªåŠ¨é€‰æ‹©ç¨€ç–åº¦
        """
        self.img_size = img_size
        self.search_region = search_region
        self.grid_resolution = grid_resolution
        self.amplitude_range = amplitude_range
        self.alpha_range = alpha_range
        self.n_nonzero_coefs = n_nonzero_coefs
        self.cross_validation = cross_validation

        # SARæˆåƒå‚æ•°
        self.fc = 1e10  # ä¸­å¿ƒé¢‘ç‡ 10 GHz
        self.B = 5e8  # å¸¦å®½ 500 MHz
        self.om_deg = 2.86  # ä¿¯ä»°è§’åº¦
        self.p = 84  # é¢‘åŸŸé‡‡æ ·ç‚¹æ•°
        self.q = 128  # å›¾åƒå°ºå¯¸

        self.om_rad = self.om_deg * np.pi / 180.0
        self.bw_ratio = self.B / self.fc

        # æ„å»ºé¢‘ç‡ç½‘æ ¼
        self.fx_range = np.linspace(self.fc * (1 - self.bw_ratio / 2), self.fc * (1 + self.bw_ratio / 2), self.p)
        self.fy_range = np.linspace(-self.fc * np.sin(self.om_rad / 2), self.fc * np.sin(self.om_rad / 2), self.p)

        # æ„å»ºå­—å…¸
        self.dictionary = None
        self.dictionary_params = None
        print(f"ğŸ¯ OMP ASCæå–å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   å›¾åƒå°ºå¯¸: {img_size}")
        print(f"   æœç´¢åŒºåŸŸ: {search_region} ç±³")
        print(f"   ç½‘æ ¼åˆ†è¾¨ç‡: {grid_resolution} ç±³")
        print(f"   OMPç¨€ç–åº¦: {n_nonzero_coefs}")
        print(f"   äº¤å‰éªŒè¯: {cross_validation}")

    def _sar_model(self, fx, fy, x, y, alpha, A=1.0):
        """
        SARæˆåƒçš„å•æ•£å°„ä¸­å¿ƒæ¨¡å‹

        Parameters:
        -----------
        fx, fy : float
            é¢‘ç‡åæ ‡
        x, y : float
            æ•£å°„ä¸­å¿ƒä½ç½® (ç±³)
        alpha : float
            é¢‘ç‡ä¾èµ–ç›¸ä½å‚æ•°
        A : float
            æ•£å°„å¹…åº¦

        Returns:
        --------
        complex
            è¯¥æ•£å°„ä¸­å¿ƒåœ¨(fx,fy)å¤„çš„å¤æ•°å“åº”
        """
        f = np.sqrt(fx**2 + fy**2)
        theta = np.arctan2(fy, fx)

        # ASCæ¨¡å‹ç®€åŒ–ç‰ˆï¼ˆåªè€ƒè™‘ä½ç½®å’Œé¢‘ç‡ä¾èµ–æ€§ï¼‰
        E1 = A * (1j * f / self.fc) ** alpha
        E2 = np.exp(-1j * 4 * np.pi * f / 3e8 * (x * np.cos(theta) + y * np.sin(theta)))

        return E1 * E2

    def _build_dictionary(self):
        """æ„å»ºOMPå­—å…¸çŸ©é˜µ"""
        print("ğŸ”§ æ„å»ºOMPå­—å…¸çŸ©é˜µ...")

        # ç”Ÿæˆä½ç½®ç½‘æ ¼
        x_min, x_max, y_min, y_max = self.search_region
        x_coords = np.arange(x_min, x_max + self.grid_resolution, self.grid_resolution)
        y_coords = np.arange(y_min, y_max + self.grid_resolution, self.grid_resolution)

        # ç”Ÿæˆå‚æ•°ç½‘æ ¼
        alpha_values = np.linspace(self.alpha_range[0], self.alpha_range[1], 11)

        # è®¡ç®—å­—å…¸å¤§å°
        n_positions = len(x_coords) * len(y_coords)
        n_alphas = len(alpha_values)
        n_atoms = n_positions * n_alphas
        n_measurements = self.p * self.p  # Kç©ºé—´æµ‹é‡æ•°

        print(f"   ä½ç½®ç½‘æ ¼: {len(x_coords)} x {len(y_coords)} = {n_positions}")
        print(f"   Alphaå‚æ•°: {n_alphas}")
        print(f"   å­—å…¸åŸå­æ€»æ•°: {n_atoms}")
        print(f"   æµ‹é‡ç»´åº¦: {n_measurements}")

        # åˆå§‹åŒ–å­—å…¸å’Œå‚æ•°
        dictionary = np.zeros((n_measurements, n_atoms), dtype=complex)
        dictionary_params = []

        atom_idx = 0
        for x in tqdm(x_coords, desc="æ„å»ºå­—å…¸", leave=False):
            for y in y_coords:
                for alpha in alpha_values:
                    # ä¸ºå½“å‰å‚æ•°ç»„åˆç”Ÿæˆå­—å…¸åŸå­
                    atom = np.zeros((self.p, self.p), dtype=complex)

                    for i, fy in enumerate(self.fy_range):
                        for j, fx in enumerate(self.fx_range):
                            atom[i, j] = self._sar_model(fx, fy, x, y, alpha)

                    # å±•å¹³å¹¶å½’ä¸€åŒ–
                    atom_flat = atom.flatten()
                    atom_flat = atom_flat / (np.linalg.norm(atom_flat) + 1e-12)

                    dictionary[:, atom_idx] = atom_flat
                    dictionary_params.append({"x": x, "y": y, "alpha": alpha})
                    atom_idx += 1

                # è½¬æ¢ä¸ºå®æ•°å­—å…¸ï¼ˆå‚ç›´å †å å®éƒ¨å’Œè™šéƒ¨ï¼‰
        dict_real = np.vstack([dictionary.real, dictionary.imag])

        self.dictionary = dict_real
        self.dictionary_params = dictionary_params

        print(f"âœ… å­—å…¸æ„å»ºå®Œæˆï¼Œå°ºå¯¸: {self.dictionary.shape}")
        return self.dictionary, self.dictionary_params

    def _k_space_to_image(self, k_space_data):
        """å°†Kç©ºé—´æ•°æ®è½¬æ¢ä¸ºå›¾åƒåŸŸ"""
        # åº”ç”¨Taylorçª—
        win = taylor(self.p, nbar=4, sll=35)
        window_2d = np.outer(win, win)
        k_windowed = k_space_data * window_2d

        # é›¶å¡«å……åˆ°å›¾åƒå°ºå¯¸
        Z = np.zeros((self.q, self.q), dtype=complex)
        start = (self.q - self.p) // 2
        Z[start : start + self.p, start : start + self.p] = k_windowed

        # IFFTåˆ°å›¾åƒåŸŸ
        img_complex = np.fft.ifftshift(np.fft.ifft2(np.fft.fftshift(Z)))
        return img_complex

    def _image_to_k_space(self, img_complex):
        """å°†å›¾åƒåŸŸæ•°æ®è½¬æ¢ä¸ºKç©ºé—´ï¼ˆMSTARæ•°æ®å¤„ç†ï¼‰"""
        # FFTåˆ°é¢‘åŸŸ
        Z_full = np.fft.fftshift(np.fft.fft2(np.fft.ifftshift(img_complex)))

        # æå–æœ‰æ•ˆKç©ºé—´åŒºåŸŸ
        start = (self.q - self.p) // 2
        k_space = Z_full[start : start + self.p, start : start + self.p]

        # å»é™¤Taylorçª—æ•ˆåº”
        win = taylor(self.p, nbar=4, sll=35)
        window_2d = np.outer(win, win)
        k_space = k_space / (window_2d + 1e-12)

        return k_space

    def extract_asc_from_raw(self, raw_file_path):
        """ä»rawæ–‡ä»¶æå–ASCå‚æ•°"""
        try:
            # è¯»å–RAWæ–‡ä»¶
            img_complex = self._read_raw_file(raw_file_path)
            return self.extract_asc_from_image(img_complex)
        except Exception as e:
            print(f"âŒ å¤„ç†RAWæ–‡ä»¶å¤±è´¥: {e}")
            return []

    def extract_asc_from_mat(self, mat_file_path):
        """ä»matæ–‡ä»¶æå–ASCå‚æ•°"""
        try:
            # è¯»å–MATæ–‡ä»¶
            mat_data = sio.loadmat(mat_file_path)
            Img = mat_data["Img"]
            phase = mat_data["phase"]

            # ç»„åˆä¸ºå¤æ•°å›¾åƒ
            img_complex = Img * np.exp(1j * phase)
            return self.extract_asc_from_image(img_complex)
        except Exception as e:
            print(f"âŒ å¤„ç†MATæ–‡ä»¶å¤±è´¥: {e}")
            return []

    def extract_asc_from_image(self, img_complex):
        """ä»å¤æ•°å›¾åƒæå–ASCå‚æ•°"""
        # ç¡®ä¿å­—å…¸å·²æ„å»º
        if self.dictionary is None:
            self._build_dictionary()

        print("ğŸ” ä½¿ç”¨OMPç®—æ³•æå–ASCå‚æ•°...")

        # è½¬æ¢åˆ°Kç©ºé—´
        k_space = self._image_to_k_space(img_complex)

        # å‡†å¤‡OMPè¾“å…¥ï¼ˆå®æ•°å‘é‡ï¼‰
        y_complex = k_space.flatten()
        y_real = np.hstack([y_complex.real, y_complex.imag])

        # å½’ä¸€åŒ–
        y_norm = np.linalg.norm(y_real)
        if y_norm > 0:
            y_real = y_real / y_norm

        # æ‰§è¡ŒOMPç®—æ³•
        if self.cross_validation:
            print("   ä½¿ç”¨äº¤å‰éªŒè¯é€‰æ‹©æœ€ä¼˜ç¨€ç–åº¦...")
            omp = OrthogonalMatchingPursuitCV(cv=3, max_iter=min(50, self.n_nonzero_coefs * 2))
        else:
            omp = OrthogonalMatchingPursuit(n_nonzero_coefs=self.n_nonzero_coefs)

        # æ‹ŸåˆOMPæ¨¡å‹
        omp.fit(self.dictionary, y_real)

        # æå–ç¨€ç–ç³»æ•°
        sparse_coefs = omp.coef_
        active_indices = np.where(np.abs(sparse_coefs) > 1e-6)[0]

        print(f"   æ£€æµ‹åˆ° {len(active_indices)} ä¸ªæ´»è·ƒæ•£å°„ä¸­å¿ƒ")

        # è½¬æ¢ä¸ºASCå‚æ•°
        asc_list = []
        for idx in active_indices:
            params = self.dictionary_params[idx].copy()
            amplitude = np.abs(sparse_coefs[idx]) * y_norm  # æ¢å¤åŸå§‹å¹…åº¦å°ºåº¦
            params["A"] = amplitude

            # æ·»åŠ å…¶ä»–é»˜è®¤å‚æ•°
            params["gamma"] = 0.0
            params["phi_prime"] = 0.0
            params["L"] = 0.0

            asc_list.append(params)

        # æŒ‰å¹…åº¦æ’åº
        asc_list.sort(key=lambda x: x["A"], reverse=True)

        return asc_list

    def _read_raw_file(self, raw_file_path):
        """è¯»å–RAWæ ¼å¼çš„å¤æ•°SARå›¾åƒ"""
        try:
            # è¯»å–äºŒè¿›åˆ¶æ•°æ®
            with open(raw_file_path, "rb") as f:
                data = np.fromfile(f, dtype=np.float32)

            # å‡è®¾æ•°æ®æ ¼å¼ï¼šå¹…åº¦+ç›¸ä½
            n_pixels = self.img_size[0] * self.img_size[1]
            if len(data) >= 2 * n_pixels:
                magnitude = data[:n_pixels].reshape(self.img_size)
                phase = data[n_pixels : 2 * n_pixels].reshape(self.img_size)

                # ç»„åˆä¸ºå¤æ•°å›¾åƒ
                img_complex = magnitude * np.exp(1j * phase)
                return img_complex
            else:
                raise ValueError(f"æ•°æ®å¤§å°ä¸åŒ¹é…: æœŸæœ›{2*n_pixels}, å®é™…{len(data)}")

        except Exception as e:
            raise RuntimeError(f"è¯»å–RAWæ–‡ä»¶å¤±è´¥: {e}")

    def reconstruct_image_from_asc(self, asc_list):
        """ä»ASCå‚æ•°åˆ—è¡¨é‡å»ºSARå›¾åƒ"""
        print("ğŸ”§ ä»ASCå‚æ•°é‡å»ºSARå›¾åƒ...")

        # åœ¨Kç©ºé—´ä¸­åˆæˆä¿¡å·
        k_space_recon = np.zeros((self.p, self.p), dtype=complex)

        for asc in asc_list:
            for i, fy in enumerate(self.fy_range):
                for j, fx in enumerate(self.fx_range):
                    k_space_recon[i, j] += self._sar_model(fx, fy, asc["x"], asc["y"], asc["alpha"], asc["A"])

        # è½¬æ¢åˆ°å›¾åƒåŸŸ
        img_recon = self._k_space_to_image(k_space_recon)
        return img_recon

    def evaluate_reconstruction(self, original_img, reconstructed_img):
        """è¯„ä¼°é‡å»ºè´¨é‡"""
        # è®¡ç®—ç›¸å¯¹RMSE
        original_norm = np.linalg.norm(original_img)
        if original_norm > 0:
            diff_norm = np.linalg.norm(reconstructed_img - original_img)
            relative_rmse = diff_norm / original_norm
        else:
            relative_rmse = float("inf")

        # è®¡ç®—ç›¸å…³ç³»æ•°
        orig_flat = original_img.flatten()
        recon_flat = reconstructed_img.flatten()
        correlation = np.corrcoef(np.abs(orig_flat), np.abs(recon_flat))[0, 1]

        return {"relative_rmse": relative_rmse, "correlation": correlation if not np.isnan(correlation) else 0.0}

    def save_results(self, asc_list, output_path):
        """ä¿å­˜ASCæå–ç»“æœä¸ºMATæ ¼å¼"""
        # è½¬æ¢ä¸ºMATLABå…¼å®¹æ ¼å¼
        scatter_all = []
        for asc in asc_list:
            params = [asc["x"], asc["y"], asc["alpha"], asc["gamma"], asc["phi_prime"], asc["L"], asc["A"]]
            scatter_all.append(params)

        # ä¿å­˜ä¸ºMATæ–‡ä»¶
        sio.savemat(output_path, {"scatter_all": np.array(scatter_all)})
        print(f"âœ… ASCç»“æœå·²ä¿å­˜åˆ°: {output_path}")

    def visualize_results(self, original_img, asc_list, save_path=None):
        """å¯è§†åŒ–ASCæå–ç»“æœ"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))

        # åŸå§‹å›¾åƒ
        axes[0, 0].imshow(np.abs(original_img), cmap="gray")
        axes[0, 0].set_title("åŸå§‹SARå›¾åƒ")
        axes[0, 0].axis("off")

        # ASCä½ç½®å åŠ 
        axes[0, 1].imshow(np.abs(original_img), cmap="gray", alpha=0.7)

        # è½¬æ¢ASCä½ç½®åˆ°åƒç´ åæ ‡
        for asc in asc_list:
            # ç®€åŒ–çš„åæ ‡è½¬æ¢
            pixel_x = int((asc["x"] - self.search_region[0]) / self.grid_resolution)
            pixel_y = int((asc["y"] - self.search_region[2]) / self.grid_resolution)

            # ç¡®ä¿åœ¨å›¾åƒèŒƒå›´å†…
            if 0 <= pixel_x < self.img_size[1] and 0 <= pixel_y < self.img_size[0]:
                axes[0, 1].plot(pixel_x, pixel_y, "r+", markersize=10, markeredgewidth=2)

        axes[0, 1].set_title(f"æ£€æµ‹åˆ°çš„ASCä½ç½® ({len(asc_list)}ä¸ª)")
        axes[0, 1].axis("off")

        # é‡å»ºå›¾åƒ
        img_recon = self.reconstruct_image_from_asc(asc_list)
        axes[1, 0].imshow(np.abs(img_recon), cmap="gray")
        axes[1, 0].set_title("OMPé‡å»ºå›¾åƒ")
        axes[1, 0].axis("off")

        # å·®å€¼å›¾åƒ
        diff_img = np.abs(original_img - img_recon)
        axes[1, 1].imshow(diff_img, cmap="hot")
        axes[1, 1].set_title("é‡å»ºè¯¯å·®")
        axes[1, 1].axis("off")

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches="tight")
            print(f"âœ… å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {save_path}")

        plt.show()


def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºOMP ASCæå–å™¨çš„ä½¿ç”¨"""
    print("ğŸš€ OMP-based ASCæå–å™¨æ¼”ç¤º")
    print("=" * 50)

    # åˆå§‹åŒ–æå–å™¨
    extractor = OMPASCExtractor(
        img_size=(128, 128),
        search_region=(-6.4, 6.4, -6.4, 6.4),
        grid_resolution=0.4,  # è¾ƒç²—çš„ç½‘æ ¼ä»¥å‡å°‘è®¡ç®—é‡
        n_nonzero_coefs=15,
        cross_validation=False,  # æ¼”ç¤ºæ—¶å…³é—­äº¤å‰éªŒè¯
    )

    # æ•°æ®è·¯å¾„é…ç½®
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    mat_root = os.path.join(project_root, "datasets", "SAR_ASC_Project", "01_Data_Processed_mat_part-tmp")
    raw_root = os.path.join(project_root, "datasets", "SAR_ASC_Project", "02_Data_Processed_raw")
    output_root = os.path.join(project_root, "traditional_method", "omp_results")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_root, exist_ok=True)

    # æŸ¥æ‰¾æµ‹è¯•æ–‡ä»¶
    test_files = []
    if os.path.exists(mat_root):
        for root, dirs, files in os.walk(mat_root):
            for file in files[:3]:  # åªå¤„ç†å‰3ä¸ªæ–‡ä»¶ä½œä¸ºæ¼”ç¤º
                if file.endswith(".mat"):
                    test_files.append(os.path.join(root, file))

    if not test_files:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡ŒMATLABé¢„å¤„ç†è„šæœ¬")
        return

    print(f"ğŸ“ æ‰¾åˆ° {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶")

    # å¤„ç†æµ‹è¯•æ–‡ä»¶
    for i, test_file in enumerate(test_files):
        print(f"\nğŸ“Š å¤„ç†æ–‡ä»¶ {i+1}/{len(test_files)}: {os.path.basename(test_file)}")

        try:
            # æå–ASC
            asc_list = extractor.extract_asc_from_mat(test_file)

            if asc_list:
                print(f"âœ… æå–åˆ° {len(asc_list)} ä¸ªæ•£å°„ä¸­å¿ƒ")

                # æ˜¾ç¤ºå‰5ä¸ªæœ€å¼ºæ•£å°„ä¸­å¿ƒ
                print("   å‰5ä¸ªæœ€å¼ºæ•£å°„ä¸­å¿ƒ:")
                for j, asc in enumerate(asc_list[:5]):
                    print(
                        f"     {j+1}. ä½ç½®:({asc['x']:.2f}, {asc['y']:.2f}), "
                        f"å¹…åº¦:{asc['A']:.3f}, Alpha:{asc['alpha']:.3f}"
                    )

                # ä¿å­˜ç»“æœ
                base_name = os.path.splitext(os.path.basename(test_file))[0]
                output_file = os.path.join(output_root, f"{base_name}_omp_asc.mat")
                extractor.save_results(asc_list, output_file)

                # é‡å»ºè¯„ä¼°
                mat_data = sio.loadmat(test_file)
                original_img = mat_data["Img"] * np.exp(1j * mat_data["phase"])
                recon_img = extractor.reconstruct_image_from_asc(asc_list)

                metrics = extractor.evaluate_reconstruction(original_img, recon_img)
                print(f"   é‡å»ºè´¨é‡ - RMSE: {metrics['relative_rmse']:.4f}, " f"ç›¸å…³ç³»æ•°: {metrics['correlation']:.4f}")

                # å¯è§†åŒ–ï¼ˆä»…ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼‰
                if i == 0:
                    viz_path = os.path.join(output_root, f"{base_name}_omp_visualization.png")
                    extractor.visualize_results(original_img, asc_list, viz_path)
            else:
                print("âš ï¸ æœªæ£€æµ‹åˆ°æ•£å°„ä¸­å¿ƒ")

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")

    print("\nğŸ‰ OMP ASCæå–æ¼”ç¤ºå®Œæˆï¼")


if __name__ == "__main__":
    main()
